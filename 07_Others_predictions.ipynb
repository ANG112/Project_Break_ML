{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones sobre:\n",
    "- Cantidad total de gasto\n",
    "    - Cantidad parciales de gasto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importación librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías para manipulación y análisis de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from toolbox_DS import *\n",
    "from toolbox_ML import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=r'.*Use subset.*of np.ndarray is not recommended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de preprocesamiento\n",
    "def establecer_indice(df, columna_id):\n",
    "    df.set_index(columna_id, inplace=True)\n",
    "    return df\n",
    "\n",
    "def convertir_a_datetime(df, columna_fecha):\n",
    "    df[columna_fecha] = pd.to_datetime(df[columna_fecha])\n",
    "    return df\n",
    "\n",
    "def convertir_a_categoricas(df, columnas):\n",
    "    df[columnas] = df[columnas].astype('category')\n",
    "    return df\n",
    "\n",
    "def eliminar_columnas(df, columnas):\n",
    "    df = df.drop(columns=columnas)\n",
    "    return df\n",
    "\n",
    "def eliminar_outliers(df, columna, valor_outlier):\n",
    "    return df[df[columna] != valor_outlier]\n",
    "\n",
    "def dividir_X_y(df, columna_objetivo):\n",
    "    X = df.drop(columns=columna_objetivo)\n",
    "    y = df[columna_objetivo]\n",
    "    return X, y\n",
    "\n",
    "# Primera parte: Preprocesamiento de los conjuntos de datos\n",
    "def preprocesar_datos(train_set, test_set, columnas_eliminar_train, columnas_eliminar_test, columna_objetivo, valor_outlier):\n",
    "    # Preprocesamiento de train_set\n",
    "    train_set = establecer_indice(train_set, 'ID')\n",
    "    train_set = convertir_a_datetime(train_set, 'Dt_Customer')\n",
    "    train_set = convertir_a_categoricas(train_set, ['Education', 'Marital_Status'])\n",
    "    train_set = eliminar_columnas(train_set, columnas_eliminar_train)\n",
    "    train_set = eliminar_outliers(train_set, 'Income', valor_outlier)\n",
    "    X_train, y_train = dividir_X_y(train_set, columna_objetivo)\n",
    "    numerical_features = X_train.select_dtypes(['int','float']).columns\n",
    "\n",
    "    # Preprocesamiento de test_set\n",
    "    test_set = establecer_indice(test_set, 'ID')\n",
    "    test_set = convertir_a_datetime(test_set, 'Dt_Customer')\n",
    "    test_set = convertir_a_categoricas(test_set, ['Education', 'Marital_Status'])\n",
    "    test_set = eliminar_columnas(test_set, columnas_eliminar_test)\n",
    "    test_set = eliminar_outliers(test_set, 'Income', valor_outlier)\n",
    "    X_test, y_test = dividir_X_y(test_set, columna_objetivo)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, numerical_features\n",
    "\n",
    "# Segunda parte: Tratamiento de variables, pipeline y transformación\n",
    "def tratamiento_y_pipeline(X_train, y_train, X_test, numerical_features, categorical_features_onehot, categorical_features_ordinal):\n",
    "    # Tratamiento de variables y pipeline\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']])\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', imputer, numerical_features),\n",
    "            ('cat_onehot', OneHotEncoder(), categorical_features_onehot),\n",
    "            ('cat_ordinal', Pipeline([\n",
    "                ('ordinal', ordinal_encoder),\n",
    "                ('scaler', MinMaxScaler())\n",
    "            ]), categorical_features_ordinal)\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocesor', preprocessor),\n",
    "        ('algoritmo', RandomForestClassifier())\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Transformación de los conjuntos de datos\n",
    "    X_train_transform = pipeline.named_steps['preprocesor'].transform(X_train)\n",
    "    X_test_transform = pipeline.named_steps['preprocesor'].transform(X_test)\n",
    "\n",
    "    # Convertir a DataFrame\n",
    "    features_transformed = pipeline.named_steps['preprocesor'].get_feature_names_out()\n",
    "    X_train_transform_df = pd.DataFrame(X_train_transform, columns=features_transformed)\n",
    "    X_test_transform_df = pd.DataFrame(X_test_transform, columns=features_transformed)\n",
    "\n",
    "    return X_train_transform_df, X_test_transform_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./data/train_set.csv')\n",
    "test_set = pd.read_csv('./data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_eliminar_train = ['income_missing', 'Year_Birth', 'Total_%_cmp', 'Dt_Customer', 'Median_amount_purchase']\n",
    "columnas_eliminar_test = ['Year_Birth', 'Total_%_cmp', 'Dt_Customer', 'Median_amount_purchase']\n",
    "categorical_features_onehot = ['Marital_Status']\n",
    "categorical_features_ordinal = ['Education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción Total_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_mnt = train_set.copy()\n",
    "test_set_mnt = test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mtn, y_train_mnt, X_test_mnt, y_test_mnt, numerical_features_mnt = preprocesar_datos(train_set_mnt,test_set_mnt,columnas_eliminar_train,columnas_eliminar_test,'Total_amount',666666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mtn.columns == X_test_mnt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome',\n",
       "       'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
       "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
       "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
       "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
       "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
       "       'Complain', 'Response', 'age', 'customes_seniority',\n",
       "       'Household_members', 'Total_purchase', 'Total_cmp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mtn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
       "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Response', 'age', 'customes_seniority',\n",
       "       'Household_members', 'Total_purchase', 'Total_cmp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features_mnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform_df_mnt, X_test_transform_df_mnt = tratamiento_y_pipeline(X_train_mtn, y_train_mnt, X_test_mnt,numerical_features_mnt,categorical_features_onehot, categorical_features_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_amount_select = ['num__Income', 'num__Kidhome', 'num__Teenhome', 'num__age','cat_onehot__Marital_Status_Alone','num__Household_members',\n",
    "       'cat_onehot__Marital_Status_Divorced',\n",
    "       'cat_onehot__Marital_Status_Married',\n",
    "       'cat_onehot__Marital_Status_Others',\n",
    "       'cat_onehot__Marital_Status_Single',\n",
    "       'cat_onehot__Marital_Status_Together',\n",
    "       'cat_onehot__Marital_Status_Widow', 'cat_ordinal__Education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LinearRegression.__init__() got an unexpected keyword argument 'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m lgb \u001b[38;5;241m=\u001b[39m LGBMRegressor(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      6\u001b[0m cat \u001b[38;5;241m=\u001b[39m CatBoostRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: LinearRegression.__init__() got an unexpected keyword argument 'max_iter'"
     ]
    }
   ],
   "source": [
    "# Instancio modelos\n",
    "\n",
    "xgb = XGBRegressor(random_state = 42)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "lgb = LGBMRegressor(random_state = 42, verbose = -3)\n",
    "cat = CatBoostRegressor(random_state=42, verbose=False)\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación cruzada:\n",
      "XGBoost: MAE = 221.709\n",
      "RandomForest: MAE = 209.420\n",
      "LightGBoost: MAE = 215.936\n",
      "CatBoost: MAE = 209.985\n",
      "LinearRegression: MAE = 245.977\n",
      "*************************\n",
      "\n",
      "El ganador es: RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Definir los nombres de los modelos y los modelos correspondientes\n",
    "model_names = ['XGBoost', 'RandomForest', 'LightGBoost', 'CatBoost', 'LinearRegression']\n",
    "model_set = [xgb, rf, lgb, cat,lin_reg]\n",
    "\n",
    "# Crear un diccionario para almacenar las métricas de validación cruzada\n",
    "metricas_cv = {}\n",
    "\n",
    "# Lista para almacenar los valores de recall\n",
    "valores = []\n",
    "\n",
    "# Realizar validación cruzada para cada modelo\n",
    "for nombre, modelo in zip(model_names, model_set):\n",
    "    # Calcular las métricas de validación cruzada\n",
    "    scores = cross_val_score(modelo, X_train_transform_df_mnt[features_amount_select], y_train_mnt, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Almacenar el resultado\n",
    "    metricas_cv[nombre] = scores\n",
    "    valores.append(np.mean(scores))\n",
    "\n",
    "# Encontrar el modelo con la mayor métrica de recall\n",
    "ganador = list(metricas_cv.keys())[np.argmax(valores)]\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la validación cruzada:\")\n",
    "for nombre, scores in metricas_cv.items():\n",
    "    print(f\"{nombre}: MAE = {-np.mean(scores):.3f}\")\n",
    "print('*'*25)\n",
    "print(f\"\\nEl ganador es: {ganador}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelización e hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo y parámetros: {'criterion': 'absolute_error', 'max_depth': 12, 'min_samples_leaf': 12, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Mejor resultado del recall para la clase positiva: -201.78001463155096\n"
     ]
    }
   ],
   "source": [
    "param_rf = {\n",
    "    'n_estimators': [80,100,200],\n",
    "    'max_depth': [10,12,13],\n",
    "    'min_samples_split': [2,3,5],\n",
    "    'min_samples_leaf': [11,12,13],\n",
    "    'criterion': 'absolute_error'\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, \n",
    "                       param_grid=param_rf, \n",
    "                       cv=5, \n",
    "                       scoring=('neg_mean_absolute_error'), \n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train_transform_df_mnt[features_amount_select], y_train_mnt)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model_rf = grid_rf.best_estimator_\n",
    "best_params_rf = grid_rf.best_params_\n",
    "print(\"Mejor modelo y parámetros:\", best_params_rf)\n",
    "\n",
    "# Imprimir el mejor resultado del MAE\n",
    "best_MAE_rf = grid_rf.best_score_\n",
    "print(\"Mejor resultado del MAE:\", best_MAE_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Característica  Importancia\n",
      "0                           num__Income     0.908930\n",
      "3                              num__age     0.026291\n",
      "1                          num__Kidhome     0.019849\n",
      "2                         num__Teenhome     0.018988\n",
      "12               cat_ordinal__Education     0.010012\n",
      "5                num__Household_members     0.008499\n",
      "7    cat_onehot__Marital_Status_Married     0.003484\n",
      "10  cat_onehot__Marital_Status_Together     0.001651\n",
      "9     cat_onehot__Marital_Status_Single     0.001502\n",
      "6   cat_onehot__Marital_Status_Divorced     0.000794\n",
      "4      cat_onehot__Marital_Status_Alone     0.000000\n",
      "8     cat_onehot__Marital_Status_Others     0.000000\n",
      "11     cat_onehot__Marital_Status_Widow     0.000000\n"
     ]
    }
   ],
   "source": [
    "importancias = best_model_rf.feature_importances_\n",
    "nombres_caracteristicas = features_amount_select\n",
    "\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Característica': nombres_caracteristicas,\n",
    "    'Importancia': importancias\n",
    "})\n",
    "\n",
    "importancias_df.sort_values(by='Importancia', ascending=False, inplace=True)\n",
    "\n",
    "print(importancias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo y parámetros: {'criterion': 'absolute_error', 'max_depth': 12, 'min_samples_leaf': 12, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Mejor resultado del recall para la clase positiva: -210.65900841503944\n"
     ]
    }
   ],
   "source": [
    " \n",
    "param_cat = {\n",
    "    'iterations': [500,1000,1500],\n",
    "    'learning_rate': [0.1,0.2,0.4],\n",
    "    'depth': [6,8,12],\n",
    "    'l2_leaf_reg': [2,3,4],\n",
    "    'min_data_in_leaf':[4,8,12],\n",
    "       \n",
    "}\n",
    "\n",
    "grid_cat = GridSearchCV(cat, \n",
    "                       param_grid=param_cat, \n",
    "                       cv=5, \n",
    "                       scoring=('neg_mean_absolute_error'), \n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_cat.fit(X_train_transform_df_mnt[features_amount_select], y_train_mnt)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model_cat = grid_cat.best_estimator_\n",
    "best_params_cat = grid_cat.best_params_\n",
    "print(\"Mejor modelo y parámetros:\", best_params_rf)\n",
    "\n",
    "# Imprimir el mejor resultado del MAE\n",
    "best_MAE_cat = grid_cat.best_score_\n",
    "print(\"Mejor resultado del MAE:\", best_MAE_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Característica  Importancia\n",
      "0                           num__Income    62.287638\n",
      "3                              num__age    11.639605\n",
      "1                          num__Kidhome     6.181174\n",
      "2                         num__Teenhome     6.127764\n",
      "12               cat_ordinal__Education     4.601861\n",
      "5                num__Household_members     3.345526\n",
      "7    cat_onehot__Marital_Status_Married     2.076928\n",
      "10  cat_onehot__Marital_Status_Together     1.263993\n",
      "9     cat_onehot__Marital_Status_Single     0.935488\n",
      "6   cat_onehot__Marital_Status_Divorced     0.844080\n",
      "11     cat_onehot__Marital_Status_Widow     0.692133\n",
      "8     cat_onehot__Marital_Status_Others     0.003439\n",
      "4      cat_onehot__Marital_Status_Alone     0.000371\n"
     ]
    }
   ],
   "source": [
    "importancias = best_model_cat.feature_importances_\n",
    "nombres_caracteristicas = features_amount_select\n",
    "\n",
    "importancias_df = pd.DataFrame({\n",
    "    'Característica': nombres_caracteristicas,\n",
    "    'Importancia': importancias\n",
    "})\n",
    "\n",
    "importancias_df.sort_values(by='Importancia', ascending=False, inplace=True)\n",
    "\n",
    "print(importancias_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación contra test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: El MAE es: 193.534609375\n",
      "RandomForest: El MAPE es: 0.9930382783861701\n",
      "CatBoost: El MAE es: 200.63835994774166\n",
      "CatBoost: El MAPE es: 1.214370051537649\n"
     ]
    }
   ],
   "source": [
    "# RandomForest:\n",
    "y_pred_mnt_rf = grid_rf.predict(X_test_transform_df_mnt[features_amount_select])\n",
    "mae = mean_absolute_error(y_test_mnt, y_pred_mnt_rf)\n",
    "print(f\"RandomForest: El MAE es: {mae}\")\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_mnt, y_pred_mnt_rf)\n",
    "print(f\"RandomForest: El MAPE es: {mape}\")\n",
    "\n",
    "# CatBoost:\n",
    "y_pred_mnt_cat = grid_cat.predict(X_test_transform_df_mnt[features_amount_select])\n",
    "mae = mean_absolute_error(y_test_mnt, y_pred_mnt_cat)\n",
    "print(f\"CatBoost: El MAE es: {mae}\")\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_mnt, y_pred_mnt_cat)\n",
    "print(f\"CatBoost: El MAPE es: {mape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/rf_mnt_1.joblib']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "path_rf = './models/rf_mnt_1.joblib'\n",
    "\n",
    "joblib.dump(grid_rf,path_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/cat_mnt_1.joblib']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cat = './models/cat_mnt_1.joblib'\n",
    "\n",
    "joblib.dump(grid_cat,path_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción gasto en fruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_mnt_fruit = train_set.copy()\n",
    "test_set_mnt_fruit = test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mtn_fruit, y_train_mnt_fruit, X_test_mnt_fruit, y_test_mnt_fruit, numerical_features_mnt = preprocesar_datos(train_set_mnt_fruit,test_set_mnt_fruit,columnas_eliminar_train,columnas_eliminar_test,'MntFruits',666666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_mtn_fruit.columns == X_test_mnt_fruit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome',\n",
       "       'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
       "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
       "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
       "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
       "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
       "       'Complain', 'Response', 'age', 'customes_seniority',\n",
       "       'Household_members', 'Total_purchase', 'Total_cmp'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_mtn_fruit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
       "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
       "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
       "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
       "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
       "       'AcceptedCmp2', 'Complain', 'Response', 'age', 'customes_seniority',\n",
       "       'Household_members', 'Total_purchase', 'Total_cmp'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_features_mnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform_df_mnt_fruit, X_test_transform_df_mnt_fruit = tratamiento_y_pipeline(X_train_mtn_fruit, y_train_mnt_fruit, X_test_mnt_fruit,numerical_features_mnt,categorical_features_onehot, categorical_features_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_amount_select = ['num__Income', 'num__Kidhome', 'num__Teenhome', 'num__age','cat_onehot__Marital_Status_Alone','num__Household_members',\n",
    "       'cat_onehot__Marital_Status_Divorced',\n",
    "       'cat_onehot__Marital_Status_Married',\n",
    "       'cat_onehot__Marital_Status_Others',\n",
    "       'cat_onehot__Marital_Status_Single',\n",
    "       'cat_onehot__Marital_Status_Together',\n",
    "       'cat_onehot__Marital_Status_Widow', 'cat_ordinal__Education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio modelos\n",
    "\n",
    "xgb = XGBRegressor(random_state = 42)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "lgb = LGBMRegressor(random_state = 42, verbose = -3)\n",
    "cat = CatBoostRegressor(random_state=42, verbose=False)\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la validación cruzada:\n",
      "XGBoost: MAE = 221.709\n",
      "RandomForest: MAE = 209.420\n",
      "LightGBoost: MAE = 215.936\n",
      "CatBoost: MAE = 209.985\n",
      "LinearRegression: MAE = 245.977\n",
      "*************************\n",
      "\n",
      "El ganador es: RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Definir los nombres de los modelos y los modelos correspondientes\n",
    "model_names = ['XGBoost', 'RandomForest', 'LightGBoost', 'CatBoost', 'LinearRegression']\n",
    "model_set = [xgb, rf, lgb, cat,lin_reg]\n",
    "\n",
    "# Crear un diccionario para almacenar las métricas de validación cruzada\n",
    "metricas_cv = {}\n",
    "\n",
    "# Lista para almacenar los valores de recall\n",
    "valores = []\n",
    "\n",
    "# Realizar validación cruzada para cada modelo\n",
    "for nombre, modelo in zip(model_names, model_set):\n",
    "    # Calcular las métricas de validación cruzada\n",
    "    scores = cross_val_score(modelo, X_train_transform_df_mnt_fruit[features_amount_select], y_train_mnt_fruit, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Almacenar el resultado\n",
    "    metricas_cv[nombre] = scores\n",
    "    valores.append(np.mean(scores))\n",
    "\n",
    "# Encontrar el modelo con la mayor métrica de recall\n",
    "ganador = list(metricas_cv.keys())[np.argmax(valores)]\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la validación cruzada:\")\n",
    "for nombre, scores in metricas_cv.items():\n",
    "    print(f\"{nombre}: MAE = {-np.mean(scores):.3f}\")\n",
    "print('*'*25)\n",
    "print(f\"\\nEl ganador es: {ganador}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
