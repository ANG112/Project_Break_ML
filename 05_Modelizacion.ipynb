{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de features y modelización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías para manipulación y análisis de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, auc\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "from toolbox_DS import *\n",
    "from toolbox_ML import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=r'.*Use subset.*of np.ndarray is not recommended')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>Response</th>\n",
       "      <th>income_missing</th>\n",
       "      <th>age</th>\n",
       "      <th>customes_seniority</th>\n",
       "      <th>Household_members</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Total_purchase</th>\n",
       "      <th>Median_amount_purchase</th>\n",
       "      <th>Total_cmp</th>\n",
       "      <th>Total_%_cmp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5675</td>\n",
       "      <td>1960</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>50611.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>98</td>\n",
       "      <td>459</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>493</td>\n",
       "      <td>22</td>\n",
       "      <td>22.409091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5543</td>\n",
       "      <td>1966</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>57811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-24</td>\n",
       "      <td>49</td>\n",
       "      <td>545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>802</td>\n",
       "      <td>25</td>\n",
       "      <td>32.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3011</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>69139.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>227</td>\n",
       "      <td>11</td>\n",
       "      <td>20.636364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>535</td>\n",
       "      <td>1987</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>81361.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-25</td>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>778</td>\n",
       "      <td>27</td>\n",
       "      <td>28.814815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10755</td>\n",
       "      <td>1976</td>\n",
       "      <td>2n Cycle</td>\n",
       "      <td>Married</td>\n",
       "      <td>23718.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-02</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>5320</td>\n",
       "      <td>1973</td>\n",
       "      <td>Master</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>44051.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>2894</td>\n",
       "      <td>1985</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>72903.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>74</td>\n",
       "      <td>1067</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>21</td>\n",
       "      <td>95.857143</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1726</td>\n",
       "      <td>1970</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>22585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-18</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>6905</td>\n",
       "      <td>1994</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>80685.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>55</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1004</td>\n",
       "      <td>21</td>\n",
       "      <td>47.809524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>6634</td>\n",
       "      <td>1979</td>\n",
       "      <td>Master</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>33462.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-07</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Year_Birth   Education Marital_Status   Income  Kidhome  \\\n",
       "0      5675        1960         PhD       Divorced  50611.0        0   \n",
       "1      5543        1966  Graduation       Together  57811.0        0   \n",
       "2      3011        1965  Graduation        Married  69139.0        0   \n",
       "3       535        1987  Graduation       Divorced  81361.0        0   \n",
       "4     10755        1976    2n Cycle        Married  23718.0        1   \n",
       "...     ...         ...         ...            ...      ...      ...   \n",
       "1785   5320        1973      Master       Divorced  44051.0        1   \n",
       "1786   2894        1985  Graduation         Single  72903.0        0   \n",
       "1787   1726        1970  Graduation         Single  22585.0        0   \n",
       "1788   6905        1994  Graduation       Together  80685.0        0   \n",
       "1789   6634        1979      Master       Divorced  33462.0        1   \n",
       "\n",
       "      Teenhome Dt_Customer  Recency  MntWines  ...  Response  income_missing  \\\n",
       "0            1  2012-10-04       98       459  ...         0               0   \n",
       "1            1  2013-06-24       49       545  ...         0               0   \n",
       "2            1  2014-01-27       23        86  ...         0               0   \n",
       "3            0  2014-02-25       18       163  ...         0               0   \n",
       "4            0  2013-09-02       76         6  ...         0               0   \n",
       "...        ...         ...      ...       ...  ...       ...             ...   \n",
       "1785         1  2013-01-29       20        79  ...         1               0   \n",
       "1786         0  2013-10-29       74      1067  ...         1               0   \n",
       "1787         0  2013-03-18       23         3  ...         1               0   \n",
       "1788         0  2012-08-22       55       241  ...         0               0   \n",
       "1789         0  2013-08-07       78        22  ...         0               0   \n",
       "\n",
       "      age  customes_seniority  Household_members  Total_amount  \\\n",
       "0      55                   3                2.0           493   \n",
       "1      49                   2                3.0           802   \n",
       "2      50                   1                3.0           227   \n",
       "3      28                   1                1.0           778   \n",
       "4      39                   2                3.0            81   \n",
       "...   ...                 ...                ...           ...   \n",
       "1785   42                   2                3.0           171   \n",
       "1786   30                   2                1.0          2013   \n",
       "1787   45                   2                1.0            81   \n",
       "1788   21                   3                2.0          1004   \n",
       "1789   36                   2                2.0            54   \n",
       "\n",
       "      Total_purchase  Median_amount_purchase  Total_cmp  Total_%_cmp  \n",
       "0                 22               22.409091          1          0.2  \n",
       "1                 25               32.080000          1          0.2  \n",
       "2                 11               20.636364          0          0.0  \n",
       "3                 27               28.814815          0          0.0  \n",
       "4                  9                9.000000          0          0.0  \n",
       "...              ...                     ...        ...          ...  \n",
       "1785              12               14.250000          0          0.0  \n",
       "1786              21               95.857143          3          0.6  \n",
       "1787               5               16.200000          1          0.2  \n",
       "1788              21               47.809524          0          0.0  \n",
       "1789               6                9.000000          0          0.0  \n",
       "\n",
       "[1790 rows x 36 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('./data/train_set.csv')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Response</th>\n",
       "      <th>age</th>\n",
       "      <th>customes_seniority</th>\n",
       "      <th>Household_members</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Total_purchase</th>\n",
       "      <th>Median_amount_purchase</th>\n",
       "      <th>Total_cmp</th>\n",
       "      <th>Total_%_cmp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2853</td>\n",
       "      <td>1980</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>51766.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>275</td>\n",
       "      <td>12</td>\n",
       "      <td>22.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10492</td>\n",
       "      <td>1959</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>38285.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8939</td>\n",
       "      <td>1959</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-16</td>\n",
       "      <td>49</td>\n",
       "      <td>382</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>730</td>\n",
       "      <td>25</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6274</td>\n",
       "      <td>1948</td>\n",
       "      <td>Master</td>\n",
       "      <td>Married</td>\n",
       "      <td>83790.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>81</td>\n",
       "      <td>1076</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1615</td>\n",
       "      <td>25</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10232</td>\n",
       "      <td>1963</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>48799.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-11-05</td>\n",
       "      <td>9</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>331</td>\n",
       "      <td>15</td>\n",
       "      <td>22.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0   2853        1980  Graduation         Single  51766.0        1         0   \n",
       "1  10492        1959  Graduation       Together  38285.0        2         1   \n",
       "2   8939        1959  Graduation       Divorced  61250.0        0         1   \n",
       "3   6274        1948      Master        Married  83790.0        0         0   \n",
       "4  10232        1963         PhD       Divorced  48799.0        0         1   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  Complain  Response  age  \\\n",
       "0  2014-03-11       74        60  ...         0         0   35   \n",
       "1  2014-06-24       96         2  ...         0         0   56   \n",
       "2  2012-12-16       49       382  ...         0         0   56   \n",
       "3  2013-11-15       81      1076  ...         0         0   67   \n",
       "4  2013-11-05        9       174  ...         0         0   52   \n",
       "\n",
       "   customes_seniority  Household_members  Total_amount  Total_purchase  \\\n",
       "0                   1                2.0           275              12   \n",
       "1                   1                5.0            10               4   \n",
       "2                   3                2.0           730              25   \n",
       "3                   2                2.0          1615              25   \n",
       "4                   2                2.0           331              15   \n",
       "\n",
       "   Median_amount_purchase  Total_cmp  Total_%_cmp  \n",
       "0               22.916667          0          0.0  \n",
       "1                2.500000          0          0.0  \n",
       "2               29.200000          0          0.0  \n",
       "3               64.600000          2          0.4  \n",
       "4               22.066667          0          0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('./data/test_set.csv')\n",
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputo los cambios que vengo aplicando al dataset.    \n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el índice\n",
    "train_set.set_index('ID', inplace=True)\n",
    "\n",
    "# Cambio tipo a datetime\n",
    "train_set['Dt_Customer'] = pd.to_datetime(train_set['Dt_Customer'])\n",
    "\n",
    "# Cambiar tipo a categóricas\n",
    "cols_to_category = ['Education', 'Marital_Status']\n",
    "train_set[cols_to_category] = train_set[cols_to_category].astype('category')\n",
    "\n",
    "# Elimino columna 'income_missing'\n",
    "train_set = train_set.drop(columns=['income_missing', 'Year_Birth','Total_%_cmp','Dt_Customer','Median_amount_purchase'])\n",
    "\n",
    "# Elimino el outlier de Income\n",
    "train_set = train_set.loc[train_set['Income'] !=666666]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también al test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio el índice\n",
    "test_set.set_index('ID', inplace=True)\n",
    "\n",
    "# Cambio tipo a datetime\n",
    "test_set['Dt_Customer'] = pd.to_datetime(test_set['Dt_Customer'])\n",
    "\n",
    "# Cambiar tipo a categóricas\n",
    "cols_to_category = ['Education', 'Marital_Status']\n",
    "test_set[cols_to_category] = test_set[cols_to_category].astype('category')\n",
    "\n",
    "# Elimino columna 'income_missing'\n",
    "test_set = test_set.drop(columns=['Year_Birth','Total_%_cmp','Dt_Customer','Median_amount_purchase'])\n",
    "\n",
    "# Elimino el outlier de Income\n",
    "test_set = test_set.loc[test_set['Income'] !=666666]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(columns='Response')\n",
    "y_train = train_set['Response']\n",
    "\n",
    "X_test = test_set.drop(columns='Response')\n",
    "y_test = test_set['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_num Index(['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
      "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
      "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
      "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
      "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
      "       'AcceptedCmp2', 'Complain', 'age', 'customes_seniority',\n",
      "       'Household_members', 'Total_amount', 'Total_purchase', 'Total_cmp'],\n",
      "      dtype='object')\n",
      "features_cat Index(['Education', 'Marital_Status'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features_num = X_train.select_dtypes(['int','float']).columns\n",
    "features_cat = X_train.select_dtypes(['object', 'category']).columns\n",
    "print('features_num', features_num)\n",
    "print('features_cat', features_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el OrdinalEncoder con el mapeo de 'education_ode'\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']])\n",
    "\n",
    "categorical_features_onehot = ['Marital_Status']\n",
    "categorical_features_ordinal = ['Education']\n",
    "numerical_features = features_num\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat_onehot', OneHotEncoder(), categorical_features_onehot),\n",
    "        ('cat_ordinal', Pipeline([\n",
    "            ('ordinal', ordinal_encoder),\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ]), categorical_features_ordinal)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocesor',preprocessor),\n",
    "    ('algoritmo', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "X_train_transform = pipeline.named_steps['preprocesor'].transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num__Income', 'num__Kidhome', 'num__Teenhome', 'num__Recency',\n",
       "       'num__MntWines', 'num__MntFruits', 'num__MntMeatProducts',\n",
       "       'num__MntFishProducts', 'num__MntSweetProducts',\n",
       "       'num__MntGoldProds', 'num__NumDealsPurchases',\n",
       "       'num__NumWebPurchases', 'num__NumCatalogPurchases',\n",
       "       'num__NumStorePurchases', 'num__NumWebVisitsMonth',\n",
       "       'num__AcceptedCmp3', 'num__AcceptedCmp4', 'num__AcceptedCmp5',\n",
       "       'num__AcceptedCmp1', 'num__AcceptedCmp2', 'num__Complain',\n",
       "       'num__age', 'num__customes_seniority', 'num__Household_members',\n",
       "       'num__Total_amount', 'num__Total_purchase', 'num__Total_cmp',\n",
       "       'cat_onehot__Marital_Status_Alone',\n",
       "       'cat_onehot__Marital_Status_Divorced',\n",
       "       'cat_onehot__Marital_Status_Married',\n",
       "       'cat_onehot__Marital_Status_Others',\n",
       "       'cat_onehot__Marital_Status_Single',\n",
       "       'cat_onehot__Marital_Status_Together',\n",
       "       'cat_onehot__Marital_Status_Widow', 'cat_ordinal__Education'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_transformed = pipeline.named_steps['preprocesor'].get_feature_names_out()\n",
    "features_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Income</th>\n",
       "      <th>num__Kidhome</th>\n",
       "      <th>num__Teenhome</th>\n",
       "      <th>num__Recency</th>\n",
       "      <th>num__MntWines</th>\n",
       "      <th>num__MntFruits</th>\n",
       "      <th>num__MntMeatProducts</th>\n",
       "      <th>num__MntFishProducts</th>\n",
       "      <th>num__MntSweetProducts</th>\n",
       "      <th>num__MntGoldProds</th>\n",
       "      <th>...</th>\n",
       "      <th>num__Total_purchase</th>\n",
       "      <th>num__Total_cmp</th>\n",
       "      <th>cat_onehot__Marital_Status_Alone</th>\n",
       "      <th>cat_onehot__Marital_Status_Divorced</th>\n",
       "      <th>cat_onehot__Marital_Status_Married</th>\n",
       "      <th>cat_onehot__Marital_Status_Others</th>\n",
       "      <th>cat_onehot__Marital_Status_Single</th>\n",
       "      <th>cat_onehot__Marital_Status_Together</th>\n",
       "      <th>cat_onehot__Marital_Status_Widow</th>\n",
       "      <th>cat_ordinal__Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50611.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23718.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>44051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>72903.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>22585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>80685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>33462.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1789 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num__Income  num__Kidhome  num__Teenhome  num__Recency  num__MntWines  \\\n",
       "0         50611.0           0.0            1.0          98.0          459.0   \n",
       "1         57811.0           0.0            1.0          49.0          545.0   \n",
       "2         69139.0           0.0            1.0          23.0           86.0   \n",
       "3         81361.0           0.0            0.0          18.0          163.0   \n",
       "4         23718.0           1.0            0.0          76.0            6.0   \n",
       "...           ...           ...            ...           ...            ...   \n",
       "1784      44051.0           1.0            1.0          20.0           79.0   \n",
       "1785      72903.0           0.0            0.0          74.0         1067.0   \n",
       "1786      22585.0           0.0            0.0          23.0            3.0   \n",
       "1787      80685.0           0.0            0.0          55.0          241.0   \n",
       "1788      33462.0           1.0            0.0          78.0           22.0   \n",
       "\n",
       "      num__MntFruits  num__MntMeatProducts  num__MntFishProducts  \\\n",
       "0                0.0                  24.0                   6.0   \n",
       "1                7.0                 114.0                  37.0   \n",
       "2               12.0                  75.0                  33.0   \n",
       "3               23.0                 424.0                  27.0   \n",
       "4                3.0                  14.0                  15.0   \n",
       "...              ...                   ...                   ...   \n",
       "1784             7.0                  58.0                   6.0   \n",
       "1785           138.0                 750.0                   0.0   \n",
       "1786             9.0                  15.0                  13.0   \n",
       "1787            45.0                 604.0                  34.0   \n",
       "1788             3.0                  18.0                   0.0   \n",
       "\n",
       "      num__MntSweetProducts  num__MntGoldProds  ...  num__Total_purchase  \\\n",
       "0                       0.0                4.0  ...                 22.0   \n",
       "1                      21.0               78.0  ...                 25.0   \n",
       "2                      15.0                6.0  ...                 11.0   \n",
       "3                      65.0               76.0  ...                 27.0   \n",
       "4                       7.0               36.0  ...                  9.0   \n",
       "...                     ...                ...  ...                  ...   \n",
       "1784                    3.0               18.0  ...                 12.0   \n",
       "1785                   19.0               39.0  ...                 21.0   \n",
       "1786                    2.0               39.0  ...                  5.0   \n",
       "1787                   26.0               54.0  ...                 21.0   \n",
       "1788                    0.0               11.0  ...                  6.0   \n",
       "\n",
       "      num__Total_cmp  cat_onehot__Marital_Status_Alone  \\\n",
       "0                1.0                               0.0   \n",
       "1                1.0                               0.0   \n",
       "2                0.0                               0.0   \n",
       "3                0.0                               0.0   \n",
       "4                0.0                               0.0   \n",
       "...              ...                               ...   \n",
       "1784             0.0                               0.0   \n",
       "1785             3.0                               0.0   \n",
       "1786             1.0                               0.0   \n",
       "1787             0.0                               0.0   \n",
       "1788             0.0                               0.0   \n",
       "\n",
       "      cat_onehot__Marital_Status_Divorced  cat_onehot__Marital_Status_Married  \\\n",
       "0                                     1.0                                 0.0   \n",
       "1                                     0.0                                 0.0   \n",
       "2                                     0.0                                 1.0   \n",
       "3                                     1.0                                 0.0   \n",
       "4                                     0.0                                 1.0   \n",
       "...                                   ...                                 ...   \n",
       "1784                                  1.0                                 0.0   \n",
       "1785                                  0.0                                 0.0   \n",
       "1786                                  0.0                                 0.0   \n",
       "1787                                  0.0                                 0.0   \n",
       "1788                                  1.0                                 0.0   \n",
       "\n",
       "      cat_onehot__Marital_Status_Others  cat_onehot__Marital_Status_Single  \\\n",
       "0                                   0.0                                0.0   \n",
       "1                                   0.0                                0.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "1784                                0.0                                0.0   \n",
       "1785                                0.0                                1.0   \n",
       "1786                                0.0                                1.0   \n",
       "1787                                0.0                                0.0   \n",
       "1788                                0.0                                0.0   \n",
       "\n",
       "      cat_onehot__Marital_Status_Together  cat_onehot__Marital_Status_Widow  \\\n",
       "0                                     0.0                               0.0   \n",
       "1                                     1.0                               0.0   \n",
       "2                                     0.0                               0.0   \n",
       "3                                     0.0                               0.0   \n",
       "4                                     0.0                               0.0   \n",
       "...                                   ...                               ...   \n",
       "1784                                  0.0                               0.0   \n",
       "1785                                  0.0                               0.0   \n",
       "1786                                  0.0                               0.0   \n",
       "1787                                  1.0                               0.0   \n",
       "1788                                  0.0                               0.0   \n",
       "\n",
       "      cat_ordinal__Education  \n",
       "0                       1.00  \n",
       "1                       0.50  \n",
       "2                       0.50  \n",
       "3                       0.50  \n",
       "4                       0.25  \n",
       "...                      ...  \n",
       "1784                    0.75  \n",
       "1785                    0.50  \n",
       "1786                    0.50  \n",
       "1787                    0.50  \n",
       "1788                    0.75  \n",
       "\n",
       "[1789 rows x 35 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transform_df = pd.DataFrame(X_train_transform, columns=(features_transformed))\n",
    "X_train_transform_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de utlizar la fórmula es que se pierde explicabilidady en este contexto es muy importante.    \n",
    "Voy a hacer algún modelo 'a mano'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección de features numéricas mediante SelectKBeest y Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num__Income', 'num__Teenhome', 'num__Recency', 'num__MntWines',\n",
       "       'num__MntFruits', 'num__MntMeatProducts', 'num__MntFishProducts',\n",
       "       'num__MntGoldProds', 'num__NumWebPurchases',\n",
       "       'num__NumCatalogPurchases', 'num__AcceptedCmp3',\n",
       "       'num__AcceptedCmp4', 'num__AcceptedCmp5', 'num__AcceptedCmp1',\n",
       "       'num__AcceptedCmp2', 'num__customes_seniority',\n",
       "       'num__Household_members', 'num__Total_amount',\n",
       "       'num__Total_purchase', 'num__Total_cmp'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector =SelectKBest(f_regression, k = 20)\n",
    "\n",
    "x_data_kbest = selector.fit_transform(X_train_transform_df, y_train)\n",
    "\n",
    "features_kbest= selector.get_feature_names_out()\n",
    "features_kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección usando modelo RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 11  6  1  1  1  1  1  1  1  1  2  1  1  1  1  3 12  9 13 14  1  1  1\n",
      "  1  1  1 15  7  4 16  5  8 10  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['num__Income', 'num__Recency', 'num__MntWines', 'num__MntFruits',\n",
       "       'num__MntMeatProducts', 'num__MntFishProducts',\n",
       "       'num__MntSweetProducts', 'num__MntGoldProds',\n",
       "       'num__NumDealsPurchases', 'num__NumCatalogPurchases',\n",
       "       'num__NumStorePurchases', 'num__NumWebVisitsMonth',\n",
       "       'num__AcceptedCmp3', 'num__age', 'num__customes_seniority',\n",
       "       'num__Household_members', 'num__Total_amount',\n",
       "       'num__Total_purchase', 'num__Total_cmp', 'cat_ordinal__Education'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instnacio modelo de clasificación\n",
    "rf_RFE = RandomForestRegressor(max_depth=5,random_state=42)\n",
    "\n",
    "# Sobre el modelo instancio el rfe\n",
    "rfe = RFE(\n",
    "    estimator=rf_RFE,\n",
    "    n_features_to_select=20,\n",
    "    step=1, \n",
    "    )\n",
    "\n",
    "# Entreno el modelo rfe\n",
    "rfe.fit(X_train_transform_df,y_train)\n",
    "print(rfe.ranking_)\n",
    "pd.DataFrame(rfe.ranking_,columns=['ranking'], index=features_transformed).sort_values('ranking')\n",
    "features_RFE= rfe.get_feature_names_out()\n",
    "features_RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección por SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio modelo clasificación\n",
    "rf_sfs = RandomForestRegressor(max_depth=5,random_state=42)\n",
    "# Instancio el modelo de la features selection\n",
    "sfs_fordward = SequentialFeatureSelector(\n",
    "    rf_sfs,\n",
    "    n_features_to_select=20,\n",
    "    cv = 3,\n",
    "    )\n",
    "\n",
    "# Entreno el modelo de features_selection\n",
    "sfs_fordward.fit(X_train_transform_df,y_train)\n",
    "features_SFS= sfs_fordward.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat_onehot__Marital_Status_Alone': 1,\n",
      " 'cat_onehot__Marital_Status_Divorced': 0,\n",
      " 'cat_onehot__Marital_Status_Married': 0,\n",
      " 'cat_onehot__Marital_Status_Others': 1,\n",
      " 'cat_onehot__Marital_Status_Single': 0,\n",
      " 'cat_onehot__Marital_Status_Together': 1,\n",
      " 'cat_onehot__Marital_Status_Widow': 1,\n",
      " 'cat_ordinal__Education': 2,\n",
      " 'num__AcceptedCmp1': 1,\n",
      " 'num__AcceptedCmp2': 2,\n",
      " 'num__AcceptedCmp3': 3,\n",
      " 'num__AcceptedCmp4': 2,\n",
      " 'num__AcceptedCmp5': 1,\n",
      " 'num__Complain': 1,\n",
      " 'num__Household_members': 3,\n",
      " 'num__Income': 2,\n",
      " 'num__Kidhome': 1,\n",
      " 'num__MntFishProducts': 2,\n",
      " 'num__MntFruits': 2,\n",
      " 'num__MntGoldProds': 3,\n",
      " 'num__MntMeatProducts': 3,\n",
      " 'num__MntSweetProducts': 2,\n",
      " 'num__MntWines': 2,\n",
      " 'num__NumCatalogPurchases': 2,\n",
      " 'num__NumDealsPurchases': 1,\n",
      " 'num__NumStorePurchases': 2,\n",
      " 'num__NumWebPurchases': 1,\n",
      " 'num__NumWebVisitsMonth': 2,\n",
      " 'num__Recency': 3,\n",
      " 'num__Teenhome': 2,\n",
      " 'num__Total_amount': 2,\n",
      " 'num__Total_cmp': 3,\n",
      " 'num__Total_purchase': 2,\n",
      " 'num__age': 1,\n",
      " 'num__customes_seniority': 3}\n"
     ]
    }
   ],
   "source": [
    "listas_features = [features_kbest,features_RFE,features_SFS]\n",
    "dicc_hard_voting = {}\n",
    "\n",
    "for col in features_transformed:\n",
    "    count = 0\n",
    "    for lista in listas_features:\n",
    "        if col in lista:\n",
    "            count +=1\n",
    "    dicc_hard_voting[col]=count\n",
    "pprint(dicc_hard_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num__Income',\n",
       " 'num__Teenhome',\n",
       " 'num__Recency',\n",
       " 'num__MntWines',\n",
       " 'num__MntFruits',\n",
       " 'num__MntMeatProducts',\n",
       " 'num__MntFishProducts',\n",
       " 'num__MntSweetProducts',\n",
       " 'num__MntGoldProds',\n",
       " 'num__NumCatalogPurchases',\n",
       " 'num__NumStorePurchases',\n",
       " 'num__NumWebVisitsMonth',\n",
       " 'num__AcceptedCmp3',\n",
       " 'num__AcceptedCmp4',\n",
       " 'num__AcceptedCmp2',\n",
       " 'num__customes_seniority',\n",
       " 'num__Household_members',\n",
       " 'num__Total_amount',\n",
       " 'num__Total_purchase',\n",
       " 'num__Total_cmp',\n",
       " 'cat_ordinal__Education']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_hard_voting = []\n",
    "\n",
    "for i,j in dicc_hard_voting.items():\n",
    "    if j == 2 or j == 3:\n",
    "        features_hard_voting.append(i)\n",
    "features_hard_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio modelos\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "xgb = XGBClassifier(max_depth=10, scale_pos_weight=ratio,random_state = 42)\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=42, class_weight='balanced')\n",
    "lgb = LGBMClassifier(max_depth=10, is_unbalance = True, objective= 'binary', random_state = 42, verbose = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el modelo XGBoost con la lista features_kbest: 0.47\n",
      "Para el modelo XGBoost con la lista features_RFE: 0.49\n",
      "Para el modelo XGBoost con la lista features_SFS: 0.56\n",
      "Para el modelo XGBoost con la lista features_hard_voting: 0.51\n",
      "Para el modelo RandomForest con la lista features_kbest: 0.33\n",
      "Para el modelo RandomForest con la lista features_RFE: 0.34\n",
      "Para el modelo RandomForest con la lista features_SFS: 0.42\n",
      "Para el modelo RandomForest con la lista features_hard_voting: 0.32\n",
      "Para el modelo LightGBM con la lista features_kbest: 0.51\n",
      "Para el modelo LightGBM con la lista features_RFE: 0.52\n",
      "Para el modelo LightGBM con la lista features_SFS: 0.58\n",
      "Para el modelo LightGBM con la lista features_hard_voting: 0.53\n"
     ]
    }
   ],
   "source": [
    "modelos = (xgb,rf,lgb)\n",
    "features_list = (features_kbest,features_RFE,features_SFS,features_hard_voting)\n",
    "model_name = ('XGBoost', 'RandomForest', 'LightGBM')\n",
    "features_name = ('features_kbest','features_RFE','features_SFS','features_hard_voting')\n",
    "\n",
    "best_result = {}\n",
    "\n",
    "for model, name in zip(modelos, model_name):\n",
    "    for i,lista in enumerate(features_list):\n",
    "        score = cross_val_score(model, X_train_transform_df[lista], y_train, cv=3, scoring=make_scorer(recall_score, pos_label=True))\n",
    "        best_score = np.mean(score)\n",
    "        best_result['name'] = (lista,best_score)\n",
    "\n",
    "        print(f'Para el modelo {name} con la lista {features_name[i]}: {best_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una lista máx. de 20 variables, el mejor algoritmo sería el LightGBM con la lista features_SFS con 0.61 de recall de la clase positiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de modelos con todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColumnTransformer' object has no attribute 'force_int_remainder_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 876, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 237, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 69, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 272, in set_params\n    valid_params = self.get_params(deep=True)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 216, in get_params\n    return self._get_params(\"steps\", deep=deep)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 47, in _get_params\n    for key, value in estimator.get_params(deep=True).items():\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 399, in get_params\n    return self._get_params(\"_transformers\", deep=deep)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 30, in _get_params\n    out = super().get_params(deep=deep)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 244, in get_params\n    value = getattr(self, key)\n            ^^^^^^^^^^^^^^^^^^\nAttributeError: 'ColumnTransformer' object has no attribute 'force_int_remainder_cols'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 35\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Realizar GridSearchCV con el scorer personalizado\u001b[39;00m\n\u001b[0;32m     28\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, \n\u001b[0;32m     29\u001b[0m                            grid, \n\u001b[0;32m     30\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     31\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39mmake_scorer(recall_score, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[0;32m     32\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Obtener el mejor modelo y parámetros\u001b[39;00m\n\u001b[0;32m     38\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m--> 970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGridSearchCV\u001b[39;00m(BaseSearchCV):\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Exhaustive search over specified parameter values for an estimator.\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m    Important members are fit, predict.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m    GridSearchCV implements a \"fit\" and a \"score\" method.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m    It also implements \"score_samples\", \"predict\", \"predict_proba\",\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;124;03m    \"decision_function\", \"transform\" and \"inverse_transform\" if they are\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;124;03m    implemented in the estimator used.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m    The parameters of the estimator used to apply these methods are optimized\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m    by cross-validated grid-search over a parameter grid.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <grid_search>`.\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m \n\u001b[0;32m   1224\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m    estimator : estimator object\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m        This is assumed to implement the scikit-learn estimator interface.\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;124;03m        Either estimator needs to provide a ``score`` function,\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;124;03m        or ``scoring`` must be passed.\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \n\u001b[0;32m   1231\u001b[0m \u001b[38;5;124;03m    param_grid : dict or list of dictionaries\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m        Dictionary with parameters names (`str`) as keys and lists of\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m        parameter settings to try as values, or a list of such\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;124;03m        dictionaries, in which case the grids spanned by each dictionary\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03m        in the list are explored. This enables searching over any sequence\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m        of parameter settings.\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    scoring : str, callable, list, tuple or dict, default=None\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m        Strategy to evaluate the performance of the cross-validated model on\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;124;03m        the test set.\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \n\u001b[0;32m   1242\u001b[0m \u001b[38;5;124;03m        If `scoring` represents a single score, one can use:\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m \n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        - a single string (see :ref:`scoring_parameter`);\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m        - a callable (see :ref:`scoring`) that returns a single value.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m        If `scoring` represents multiple scores, one can use:\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m \n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m        - a list or tuple of unique strings;\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;124;03m        - a callable returning a dictionary where the keys are the metric\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;124;03m          names and the values are the metric scores;\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;124;03m        - a dictionary with metric names as keys and callables a values.\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m        See :ref:`multimetric_grid_search` for an example.\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m \n\u001b[0;32m   1256\u001b[0m \u001b[38;5;124;03m    n_jobs : int, default=None\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;124;03m        Number of jobs to run in parallel.\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m        for more details.\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \n\u001b[0;32m   1262\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: v0.20\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;124;03m           `n_jobs` default changed from 1 to None\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m    refit : bool, str, or callable, default=True\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m        Refit an estimator using the best found parameters on the whole\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m        dataset.\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m        For multiple metric evaluation, this needs to be a `str` denoting the\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;124;03m        scorer that would be used to find the best parameters for refitting\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03m        the estimator at the end.\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \n\u001b[0;32m   1273\u001b[0m \u001b[38;5;124;03m        Where there are considerations other than maximum score in\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;124;03m        choosing a best estimator, ``refit`` can be set to a function which\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;124;03m        returns the selected ``best_index_`` given ``cv_results_``. In that\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;124;03m        case, the ``best_estimator_`` and ``best_params_`` will be set\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m        according to the returned ``best_index_`` while the ``best_score_``\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;124;03m        attribute will not be available.\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m        The refitted estimator is made available at the ``best_estimator_``\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m        attribute and permits using ``predict`` directly on this\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m        ``GridSearchCV`` instance.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m        Also for multiple metric evaluation, the attributes ``best_index_``,\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m        ``best_score_`` and ``best_params_`` will only be available if\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;124;03m        ``refit`` is set and all of them will be determined w.r.t this specific\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;124;03m        scorer.\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m \n\u001b[0;32m   1289\u001b[0m \u001b[38;5;124;03m        See ``scoring`` parameter to know more about multiple metric\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m        evaluation.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03m        See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;124;03m        to see how to design a custom selection strategy using a callable\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m        via `refit`.\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m \n\u001b[0;32m   1296\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.20\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;124;03m            Support for callable added.\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \n\u001b[0;32m   1299\u001b[0m \u001b[38;5;124;03m    cv : int, cross-validation generator or an iterable, default=None\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;124;03m        Determines the cross-validation splitting strategy.\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m        Possible inputs for cv are:\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \n\u001b[0;32m   1303\u001b[0m \u001b[38;5;124;03m        - None, to use the default 5-fold cross validation,\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;124;03m        - integer, to specify the number of folds in a `(Stratified)KFold`,\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m        - :term:`CV splitter`,\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m        - An iterable yielding (train, test) splits as arrays of indices.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03m        For integer/None inputs, if the estimator is a classifier and ``y`` is\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m        either binary or multiclass, :class:`StratifiedKFold` is used. In all\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m        other cases, :class:`KFold` is used. These splitters are instantiated\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m        with `shuffle=False` so the splits will be the same across calls.\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m        Refer :ref:`User Guide <cross_validation>` for the various\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m        cross-validation strategies that can be used here.\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.22\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m            ``cv`` default value if None changed from 3-fold to 5-fold.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \n\u001b[0;32m   1319\u001b[0m \u001b[38;5;124;03m    verbose : int\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03m        Controls the verbosity: the higher, the more messages.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m        - >1 : the computation time for each fold and parameter candidate is\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03m          displayed;\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m        - >2 : the score is also displayed;\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;124;03m        - >3 : the fold and candidate parameter indexes are also displayed\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;124;03m          together with the starting time of the computation.\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \n\u001b[0;32m   1328\u001b[0m \u001b[38;5;124;03m    pre_dispatch : int, or str, default='2*n_jobs'\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;124;03m        Controls the number of jobs that get dispatched during parallel\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124;03m        execution. Reducing this number can be useful to avoid an\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;124;03m        explosion of memory consumption when more jobs get dispatched\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;124;03m        than CPUs can process. This parameter can be:\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \n\u001b[0;32m   1334\u001b[0m \u001b[38;5;124;03m            - None, in which case all the jobs are immediately\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;124;03m              created and spawned. Use this for lightweight and\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m              fast-running jobs, to avoid delays due to on-demand\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m              spawning of the jobs\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m            - An int, giving the exact number of total jobs that are\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m              spawned\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \n\u001b[0;32m   1342\u001b[0m \u001b[38;5;124;03m            - A str, giving an expression as a function of n_jobs,\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;124;03m              as in '2*n_jobs'\u001b[39;00m\n\u001b[0;32m   1344\u001b[0m \n\u001b[0;32m   1345\u001b[0m \u001b[38;5;124;03m    error_score : 'raise' or numeric, default=np.nan\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;124;03m        Value to assign to the score if an error occurs in estimator fitting.\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;124;03m        If set to 'raise', the error is raised. If a numeric value is given,\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;124;03m        FitFailedWarning is raised. This parameter does not affect the refit\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;124;03m        step, which will always raise the error.\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    return_train_score : bool, default=False\u001b[39;00m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;124;03m        If ``False``, the ``cv_results_`` attribute will not include training\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;124;03m        scores.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;124;03m        Computing training scores is used to get insights on how different\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03m        parameter settings impact the overfitting/underfitting trade-off.\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m        However computing the scores on the training set can be computationally\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;124;03m        expensive and is not strictly required to select the parameters that\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;124;03m        yield the best generalization performance.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \n\u001b[0;32m   1360\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.19\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m \n\u001b[0;32m   1362\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.21\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;124;03m            Default value was changed from ``True`` to ``False``\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \n\u001b[0;32m   1365\u001b[0m \u001b[38;5;124;03m    Attributes\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;124;03m    cv_results_ : dict of numpy (masked) ndarrays\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;124;03m        A dict with keys as column headers and values as columns, that can be\u001b[39;00m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m        imported into a pandas ``DataFrame``.\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \n\u001b[0;32m   1371\u001b[0m \u001b[38;5;124;03m        For instance the below given table\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \n\u001b[0;32m   1373\u001b[0m \u001b[38;5;124;03m        +------------+-----------+------------+-----------------+---+---------+\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m        +============+===========+============+=================+===+=========+\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m        |  'poly'    |     --    |      2     |       0.80      |...|    2    |\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;124;03m        +------------+-----------+------------+-----------------+---+---------+\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m        |  'poly'    |     --    |      3     |       0.70      |...|    4    |\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m        +------------+-----------+------------+-----------------+---+---------+\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;124;03m        |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;124;03m        +------------+-----------+------------+-----------------+---+---------+\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;124;03m        |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\u001b[39;00m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;124;03m        +------------+-----------+------------+-----------------+---+---------+\u001b[39;00m\n\u001b[0;32m   1384\u001b[0m \n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m        will be represented by a ``cv_results_`` dict of::\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \n\u001b[0;32m   1387\u001b[0m \u001b[38;5;124;03m            {\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;124;03m            'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m                                         mask = [False False False False]...)\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m            'param_gamma': masked_array(data = [-- -- 0.1 0.2],\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m                                        mask = [ True  True False False]...),\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03m            'param_degree': masked_array(data = [2.0 3.0 -- --],\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;124;03m                                         mask = [False False  True  True]...),\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;124;03m            'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;124;03m            'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;124;03m            'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;124;03m            'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;124;03m            'rank_test_score'    : [2, 4, 3, 1],\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03m            'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m            'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m            'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\u001b[39;00m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;124;03m            'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\u001b[39;00m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;124;03m            'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m            'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m            'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03m            'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m            'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03m            }\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m        NOTE\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m        The key ``'params'`` is used to store a list of parameter\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;124;03m        settings dicts for all the parameter candidates.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124;03m        ``std_score_time`` are all in seconds.\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \n\u001b[0;32m   1418\u001b[0m \u001b[38;5;124;03m        For multi-metric evaluation, the scores for all the scorers are\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;124;03m        available in the ``cv_results_`` dict at the keys ending with that\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;124;03m        scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;124;03m        above. ('split0_test_precision', 'mean_train_precision' etc.)\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \n\u001b[0;32m   1423\u001b[0m \u001b[38;5;124;03m    best_estimator_ : estimator\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m        Estimator that was chosen by the search, i.e. estimator\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;124;03m        which gave highest score (or smallest loss if specified)\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;124;03m        on the left out data. Not available if ``refit=False``.\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m \n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m        See ``refit`` parameter for more information on allowed values.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \n\u001b[0;32m   1430\u001b[0m \u001b[38;5;124;03m    best_score_ : float\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m        Mean cross-validated score of the best_estimator\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m \n\u001b[0;32m   1433\u001b[0m \u001b[38;5;124;03m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;124;03m        specified.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[0;32m   1436\u001b[0m \u001b[38;5;124;03m        This attribute is not available if ``refit`` is a function.\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \n\u001b[0;32m   1438\u001b[0m \u001b[38;5;124;03m    best_params_ : dict\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m        Parameter setting that gave the best results on the hold out data.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \n\u001b[0;32m   1441\u001b[0m \u001b[38;5;124;03m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;124;03m        specified.\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m \n\u001b[0;32m   1444\u001b[0m \u001b[38;5;124;03m    best_index_ : int\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03m        The index (of the ``cv_results_`` arrays) which corresponds to the best\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03m        candidate parameter setting.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03m        The dict at ``search.cv_results_['params'][search.best_index_]`` gives\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;124;03m        the parameter setting for the best model, that gives the highest\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;124;03m        mean score (``search.best_score_``).\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;124;03m        specified.\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m \n\u001b[0;32m   1455\u001b[0m \u001b[38;5;124;03m    scorer_ : function or a dict\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;124;03m        Scorer function used on the held out data to choose the best\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124;03m        parameters for the model.\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m \n\u001b[0;32m   1459\u001b[0m \u001b[38;5;124;03m        For multi-metric evaluation, this attribute holds the validated\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;124;03m        ``scoring`` dict which maps the scorer key to the scorer callable.\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \n\u001b[0;32m   1462\u001b[0m \u001b[38;5;124;03m    n_splits_ : int\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;124;03m        The number of cross-validation splits (folds/iterations).\u001b[39;00m\n\u001b[0;32m   1464\u001b[0m \n\u001b[0;32m   1465\u001b[0m \u001b[38;5;124;03m    refit_time_ : float\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03m        Seconds used for refitting the best model on the whole dataset.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m        This is present only if ``refit`` is not False.\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    multimetric_ : bool\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m        Whether or not the scorers compute several metrics.\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m \n\u001b[0;32m   1475\u001b[0m \u001b[38;5;124;03m    classes_ : ndarray of shape (n_classes,)\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03m        The classes labels. This is present only if ``refit`` is specified and\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03m        the underlying estimator is a classifier.\u001b[39;00m\n\u001b[0;32m   1478\u001b[0m \n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03m    n_features_in_ : int\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m        Number of features seen during :term:`fit`. Only defined if\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03m        `best_estimator_` is defined (see the documentation for the `refit`\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03m        parameter for more details) and that `best_estimator_` exposes\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;124;03m        `n_features_in_` when fit.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \n\u001b[0;32m   1485\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.24\u001b[39;00m\n\u001b[0;32m   1486\u001b[0m \n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;124;03m        Names of features seen during :term:`fit`. Only defined if\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;124;03m        `best_estimator_` is defined (see the documentation for the `refit`\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;124;03m        parameter for more details) and that `best_estimator_` exposes\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;124;03m        `feature_names_in_` when fit.\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \n\u001b[0;32m   1493\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   1494\u001b[0m \n\u001b[0;32m   1495\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;124;03m    ParameterGrid : Generates all the combinations of a hyperparameter grid.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;124;03m    train_test_split : Utility function to split the data into a development\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m        set usable for fitting a GridSearchCV instance and an evaluation set\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;124;03m        for its final evaluation.\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;124;03m    sklearn.metrics.make_scorer : Make a scorer from a performance metric or\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;124;03m        loss function.\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;124;03m    The parameters selected are those that maximize the score of the left out\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;124;03m    data, unless an explicit score is passed in which case it is used instead.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \n\u001b[0;32m   1509\u001b[0m \u001b[38;5;124;03m    If `n_jobs` was set to a value higher than one, the data is copied for each\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;124;03m    point in the grid (and not `n_jobs` times). This is done for efficiency\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;124;03m    reasons if individual jobs take very little time, but may raise errors if\u001b[39;00m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;124;03m    the dataset is large and not enough memory is available.  A workaround in\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03m    this case is to set `pre_dispatch`. Then, the memory is copied only\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;124;03m    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;124;03m    n_jobs`.\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \n\u001b[0;32m   1517\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;124;03m    >>> from sklearn import svm, datasets\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.model_selection import GridSearchCV\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;124;03m    >>> iris = datasets.load_iris()\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;124;03m    >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;124;03m    >>> svc = svm.SVC()\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;124;03m    >>> clf = GridSearchCV(svc, parameters)\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;124;03m    >>> clf.fit(iris.data, iris.target)\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;124;03m    GridSearchCV(estimator=SVC(),\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m \u001b[38;5;124;03m                 param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;124;03m    >>> sorted(clf.cv_results_.keys())\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;124;03m    ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;124;03m     'param_C', 'param_kernel', 'params',...\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;124;03m     'rank_test_score', 'split0_test_score',...\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;124;03m     'split2_test_score', ...\u001b[39;00m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m     'std_fit_time', 'std_score_time', 'std_test_score']\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m     _required_parameters \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1538\u001b[0m     _parameter_constraints: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mBaseSearchCV\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_grid\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mlist\u001b[39m],\n\u001b[0;32m   1541\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# *SearchCV.estimator is not validated yet\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    889\u001b[0m )\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    891\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run fit with all sets of parameters.\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \n\u001b[0;32m    893\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m    X : array-like of shape (n_samples, n_features)\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m        Training vector, where `n_samples` is the number of samples and\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m        `n_features` is the number of features.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m    y : array-like of shape (n_samples, n_output) \\\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m        or (n_samples,), default=None\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        Target relative to X for classification or regression;\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m        None for unsupervised learning.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03m    **params : dict of str -> object\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;124;03m        Parameters passed to the ``fit`` method of the estimator, the scorer,\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03m        and the CV splitter.\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m        If a fit parameter is an array-like whose length is equal to\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m        `num_samples` then it will be split across CV groups along with `X`\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m        and `y`. For example, the :term:`sample_weight` parameter is split\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m        because `len(sample_weights) = len(X)`.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;124;03m    self : object\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m        Instance of fitted estimator.\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\n\u001b[0;32m    920\u001b[0m     scorers, refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scorers()\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     51\u001b[0m def __call__(self, iterable):\n\u001b[0;32m     52\u001b[0m     \"\"\"Dispatch the tasks and return the results.\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m     Parameters\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m         List of results of the tasks.\n\u001b[0;32m     64\u001b[0m     \"\"\"\n\u001b[0;32m     65\u001b[0m     # Capture the thread-local scikit-learn configuration at the time\n\u001b[0;32m     66\u001b[0m     # Parallel.__call__ is issued since the tasks can be dispatched\n\u001b[1;32m---> 67\u001b[0m     # in a different thread depending on the backend and on the value of\n\u001b[0;32m     68\u001b[0m     # pre_dispatch and n_jobs.\n\u001b[0;32m     69\u001b[0m     config = get_config()\n\u001b[0;32m     70\u001b[0m     iterable_with_config = (\n\u001b[0;32m     71\u001b[0m         (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m         for delayed_func, args, kwargs in iterable\n\u001b[0;32m     73\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Alfonso\\miniconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ColumnTransformer' object has no attribute 'force_int_remainder_cols'"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocesor', preprocessor),\n",
    "    ('algoritmo', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# Definir el grid de hiperparámetros\n",
    "grid = [\n",
    "    {'algoritmo': [RandomForestClassifier()],\n",
    "     'algoritmo__max_depth': [5, 10, 15],\n",
    "     'algoritmo__n_estimators': [50, 100, 200],\n",
    "     'algoritmo__class_weight':['balanced']},\n",
    "   \n",
    "    {'algoritmo': [XGBClassifier()],\n",
    "     'algoritmo__learning_rate': [0.1, 0.3, 0.5],\n",
    "     'algoritmo__n_estimators': [100, 500, 1000],\n",
    "     'algoritmo__scale_pos_weight':[ratio]},\n",
    "    \n",
    "    {'algoritmo': [LGBMClassifier()],\n",
    "     'algoritmo__learnin_rate': [0.1, 0.3, 0.5],\n",
    "     'algoritmo__n_estimators': [100, 500, 1000],\n",
    "     'algoritmo__is_unbalance' : [True],\n",
    "     'algoritmo__objective': ['binary']}\n",
    "]\n",
    "\n",
    "\n",
    "# Realizar GridSearchCV con el scorer personalizado\n",
    "grid_search = GridSearchCV(pipe, \n",
    "                           grid, \n",
    "                           cv=5, \n",
    "                           scoring=make_scorer(recall_score, pos_label=True), \n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Mejor modelo y parámetros:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617749825296995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_algoritmo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.661775</td>\n",
       "      <td>0.031112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.661775</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.650454</td>\n",
       "      <td>0.049566</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.590915</td>\n",
       "      <td>0.040551</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.565059</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.565059</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.565059</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.561286</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.561146</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.557512</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.557372</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.557372</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.553878</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.553739</td>\n",
       "      <td>0.049797</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.542628</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.516771</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.516771</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.516771</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.513068</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.513068</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.513068</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.435010</td>\n",
       "      <td>0.042153</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.397904</td>\n",
       "      <td>0.045916</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.386653</td>\n",
       "      <td>0.041478</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.345772</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.334521</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.327114</td>\n",
       "      <td>0.021750</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      param_algoritmo  mean_test_score  \\\n",
       "0                            RandomForestClassifier()         0.661775   \n",
       "1                            RandomForestClassifier()         0.661775   \n",
       "2                            RandomForestClassifier()         0.650454   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...         0.590915   \n",
       "24                                   LGBMClassifier()         0.565059   \n",
       "21                                   LGBMClassifier()         0.565059   \n",
       "18                                   LGBMClassifier()         0.565059   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...         0.561286   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...         0.561146   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...         0.557512   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...         0.557372   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...         0.557372   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...         0.553878   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...         0.553739   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...         0.542628   \n",
       "20                                   LGBMClassifier()         0.516771   \n",
       "23                                   LGBMClassifier()         0.516771   \n",
       "26                                   LGBMClassifier()         0.516771   \n",
       "25                                   LGBMClassifier()         0.513068   \n",
       "19                                   LGBMClassifier()         0.513068   \n",
       "22                                   LGBMClassifier()         0.513068   \n",
       "4                            RandomForestClassifier()         0.435010   \n",
       "5                            RandomForestClassifier()         0.397904   \n",
       "3                            RandomForestClassifier()         0.386653   \n",
       "7                            RandomForestClassifier()         0.345772   \n",
       "6                            RandomForestClassifier()         0.334521   \n",
       "8                            RandomForestClassifier()         0.327114   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.031112                1  \n",
       "1         0.035246                1  \n",
       "2         0.049566                3  \n",
       "9         0.040551                4  \n",
       "24        0.060294                5  \n",
       "21        0.060294                5  \n",
       "18        0.060294                5  \n",
       "15        0.019818                8  \n",
       "10        0.053510                9  \n",
       "17        0.023585               10  \n",
       "11        0.040798               11  \n",
       "13        0.056333               11  \n",
       "16        0.012183               13  \n",
       "12        0.049797               14  \n",
       "14        0.044418               15  \n",
       "20        0.047744               16  \n",
       "23        0.047744               16  \n",
       "26        0.047744               16  \n",
       "25        0.048181               19  \n",
       "19        0.048181               19  \n",
       "22        0.048181               19  \n",
       "4         0.042153               22  \n",
       "5         0.045916               23  \n",
       "3         0.041478               24  \n",
       "7         0.038481               25  \n",
       "6         0.032543               26  \n",
       "8         0.021750               27  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "df_cv_results[['param_algoritmo','mean_test_score','std_test_score','rank_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo un pipeline con todas las variables, el mejor sería un RandomForest con una recall de la clase positiva de 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo y parámetros: {'algoritmo__class_weight': 'balanced', 'algoritmo__max_depth': 6, 'algoritmo__min_samples_leaf': 12, 'algoritmo__min_samples_split': 3, 'algoritmo__n_estimators': 400}\n",
      "Mejor resultado del recall para la clase positiva: 0.7138364779874213\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor),\n",
    "    ('algoritmo', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param = {\n",
    "    'algoritmo__n_estimators': [400,450,500],\n",
    "    'algoritmo__max_depth': [5, 6,7],\n",
    "    'algoritmo__min_samples_split': [3,4,5],\n",
    "    'algoritmo__min_samples_leaf': [8,10,12],\n",
    "    'algoritmo__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipe, \n",
    "                       param_grid=param, \n",
    "                       cv=5, \n",
    "                       scoring=make_scorer(recall_score, pos_label=True), \n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model_rf = grid_rf.best_estimator_\n",
    "best_params_rf = grid_rf.best_params_\n",
    "print(\"Mejor modelo y parámetros:\", best_params_rf)\n",
    "\n",
    "# Imprimir el mejor resultado del recall para la clase positiva\n",
    "best_recall_rf = grid_rf.best_score_\n",
    "print(\"Mejor resultado del recall para la clase positiva:\", best_recall_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num__Total_cmp                         0.152178\n",
      "num__Recency                           0.083636\n",
      "num__Total_amount                      0.074611\n",
      "num__MntGoldProds                      0.064590\n",
      "num__MntMeatProducts                   0.058411\n",
      "num__Household_members                 0.050621\n",
      "num__AcceptedCmp5                      0.045891\n",
      "num__Income                            0.045819\n",
      "num__NumCatalogPurchases               0.045677\n",
      "num__MntWines                          0.045527\n",
      "num__AcceptedCmp3                      0.042503\n",
      "num__customes_seniority                0.035559\n",
      "num__NumWebVisitsMonth                 0.033680\n",
      "num__AcceptedCmp1                      0.028701\n",
      "num__NumStorePurchases                 0.025045\n",
      "num__MntSweetProducts                  0.021291\n",
      "num__NumWebPurchases                   0.018903\n",
      "num__Total_purchase                    0.018277\n",
      "num__MntFruits                         0.017832\n",
      "num__Teenhome                          0.016212\n",
      "num__NumDealsPurchases                 0.014856\n",
      "num__MntFishProducts                   0.014551\n",
      "num__age                               0.011403\n",
      "cat_ordinal__Education                 0.008834\n",
      "cat_onehot__Marital_Status_Single      0.007403\n",
      "cat_onehot__Marital_Status_Married     0.004519\n",
      "cat_onehot__Marital_Status_Together    0.004493\n",
      "num__AcceptedCmp4                      0.004194\n",
      "num__Kidhome                           0.003361\n",
      "cat_onehot__Marital_Status_Divorced    0.000898\n",
      "cat_onehot__Marital_Status_Widow       0.000455\n",
      "num__AcceptedCmp2                      0.000062\n",
      "num__Complain                          0.000006\n",
      "cat_onehot__Marital_Status_Alone       0.000000\n",
      "cat_onehot__Marital_Status_Others      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Acceder al modelo dentro del Pipeline\n",
    "random_forest_model = best_model_rf.named_steps['algoritmo']\n",
    "\n",
    "# Obtener las importancias de las características\n",
    "feature_importances = random_forest_model.feature_importances_\n",
    "\n",
    "if 'preprocesador' in best_model_rf.named_steps:\n",
    "    preprocessor = best_model_rf.named_steps['preprocesador']\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    importances_series = pd.Series(feature_importances, index=feature_names)\n",
    "    print(importances_series.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LigthGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[LightGBM] [Info] Number of positive: 269, number of negative: 1520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1853\n",
      "[LightGBM] [Info] Number of data points in the train set: 1789, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.150363 -> initscore=-1.731754\n",
      "[LightGBM] [Info] Start training from score -1.731754\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mejor modelo y parámetros: {'algoritmo__is_unbalance': True, 'algoritmo__learning_rate': 0.09, 'algoritmo__max_depth': 4, 'algoritmo__min_child_samples': 2, 'algoritmo__min_child_weight': 10, 'algoritmo__n_estimators': 100, 'algoritmo__objective': 'binary'}\n",
      "Mejor resultado del recall para la clase positiva: 0.7434661076170511\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor),\n",
    "    ('algoritmo', LGBMClassifier())\n",
    "])\n",
    "\n",
    "param = {\n",
    "    'algoritmo__max_depth': [4,5, 6],\n",
    "    'algoritmo__min_child_samples': [2,4,8],\n",
    "    'algoritmo__min_child_weight': [4, 8,10],\n",
    "    'algoritmo__learning_rate': [0.09, 0.1, 0.2],\n",
    "    'algoritmo__n_estimators': [100, 200, 300],\n",
    "    'algoritmo__is_unbalance' : [True],\n",
    "    'algoritmo__objective': ['binary'],\n",
    "}\n",
    "\n",
    "grid_lgb = GridSearchCV(pipe, \n",
    "                       param_grid=param, \n",
    "                       cv=5, \n",
    "                       scoring=make_scorer(recall_score, pos_label=True), \n",
    "                       n_jobs=-1,\n",
    "                       verbose= 1)\n",
    "\n",
    "grid_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model_lgb = grid_lgb.best_estimator_\n",
    "best_params_lgb = grid_lgb.best_params_\n",
    "print(\"Mejor modelo y parámetros:\", best_params_lgb)\n",
    "\n",
    "# Imprimir el mejor resultado del recall para la clase positiva\n",
    "best_recall_lgb = grid_lgb.best_score_\n",
    "print(\"Mejor resultado del recall para la clase positiva:\", best_recall_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num__Recency                           145\n",
      "num__MntMeatProducts                    67\n",
      "num__MntGoldProds                       62\n",
      "num__Total_cmp                          58\n",
      "num__age                                55\n",
      "num__NumStorePurchases                  54\n",
      "num__NumWebVisitsMonth                  50\n",
      "num__MntSweetProducts                   48\n",
      "num__MntWines                           46\n",
      "num__Household_members                  44\n",
      "num__customes_seniority                 44\n",
      "num__Income                             43\n",
      "cat_ordinal__Education                  41\n",
      "num__MntFruits                          31\n",
      "num__Total_amount                       28\n",
      "num__MntFishProducts                    24\n",
      "num__NumCatalogPurchases                24\n",
      "num__NumWebPurchases                    18\n",
      "num__Teenhome                           16\n",
      "num__NumDealsPurchases                  16\n",
      "num__Total_purchase                     15\n",
      "cat_onehot__Marital_Status_Married      14\n",
      "num__AcceptedCmp5                       14\n",
      "cat_onehot__Marital_Status_Together     10\n",
      "num__Kidhome                             9\n",
      "cat_onehot__Marital_Status_Single        8\n",
      "num__AcceptedCmp3                        6\n",
      "num__AcceptedCmp4                        3\n",
      "num__AcceptedCmp1                        2\n",
      "cat_onehot__Marital_Status_Divorced      1\n",
      "num__Complain                            0\n",
      "cat_onehot__Marital_Status_Alone         0\n",
      "num__AcceptedCmp2                        0\n",
      "cat_onehot__Marital_Status_Others        0\n",
      "cat_onehot__Marital_Status_Widow         0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Acceder al modelo dentro del Pipeline\n",
    "lgb_model = best_model_lgb.named_steps['algoritmo']\n",
    "\n",
    "# Obtener las importancias de las características\n",
    "feature_importances = lgb_model.feature_importances_\n",
    "\n",
    "if 'preprocesador' in best_model_lgb.named_steps:\n",
    "    preprocessor = best_model_lgb.named_steps['preprocesador']\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    importances_series = pd.Series(feature_importances, index=feature_names)\n",
    "    print(importances_series.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Mejor modelo y parámetros: {'algoritmo__colsample_bytree': 0.7, 'algoritmo__gamma': 0.2, 'algoritmo__max_depth': 5, 'algoritmo__min_child_weight': 8, 'algoritmo__n_estimators': 300, 'algoritmo__scale_pos_weight': 5.650557620817844, 'algoritmo__subsample': 0.9}\n",
      "Mejor resultado del recall para la clase positiva: 0.6431865828092242\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocesador', preprocessor),\n",
    "    ('algoritmo', XGBClassifier())\n",
    "])\n",
    "\n",
    "param = {\n",
    "    'algoritmo__n_estimators': [300, 400, 450],\n",
    "    'algoritmo__max_depth': [4, 5, 6],\n",
    "    'algoritmo__min_child_weight': [6, 8, 10],  # Equivalente a min_samples_leaf en RandomForest\n",
    "    'algoritmo__gamma': [0, 0.1, 0.2],  # Parámetro para controlar la regularización\n",
    "    'algoritmo__subsample': [0.7, 0.8, 0.9],  # Porcentaje de muestras usadas para cada árbol\n",
    "    'algoritmo__colsample_bytree': [0.7, 0.8, 0.9],  # Porcentaje de características usadas para cada árbol\n",
    "    'algoritmo__scale_pos_weight': [ratio]  # Ponderación de clases para datasets desbalanceados\n",
    "}\n",
    "\n",
    "\n",
    "grid_xgb = GridSearchCV(pipe, \n",
    "                       param_grid=param, \n",
    "                       cv=5, \n",
    "                       scoring=make_scorer(recall_score, pos_label=True), \n",
    "                       n_jobs=-1,\n",
    "                       verbose= 3)\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y parámetros\n",
    "best_model_xgb = grid_xgb.best_estimator_\n",
    "best_params_xgb = grid_xgb.best_params_\n",
    "print(\"Mejor modelo y parámetros:\", best_params_xgb)\n",
    "\n",
    "# Imprimir el mejor resultado del recall para la clase positiva\n",
    "best_recall_xgb = grid_xgb.best_score_\n",
    "print(\"Mejor resultado del recall para la clase positiva:\", best_recall_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num__Total_cmp                         0.220172\n",
      "num__customes_seniority                0.068627\n",
      "num__Household_members                 0.066530\n",
      "cat_onehot__Marital_Status_Single      0.038947\n",
      "num__NumWebVisitsMonth                 0.036663\n",
      "num__Recency                           0.035630\n",
      "num__Teenhome                          0.034904\n",
      "num__AcceptedCmp5                      0.034557\n",
      "cat_ordinal__Education                 0.032742\n",
      "num__NumStorePurchases                 0.029930\n",
      "num__AcceptedCmp3                      0.029727\n",
      "num__Kidhome                           0.028177\n",
      "num__AcceptedCmp1                      0.027486\n",
      "cat_onehot__Marital_Status_Together    0.027044\n",
      "num__MntMeatProducts                   0.025993\n",
      "num__NumDealsPurchases                 0.023398\n",
      "num__MntGoldProds                      0.023347\n",
      "cat_onehot__Marital_Status_Married     0.022462\n",
      "num__NumCatalogPurchases               0.021637\n",
      "num__Income                            0.019905\n",
      "num__NumWebPurchases                   0.019852\n",
      "num__Total_purchase                    0.018032\n",
      "num__Total_amount                      0.017463\n",
      "num__MntWines                          0.016851\n",
      "num__AcceptedCmp4                      0.015594\n",
      "num__MntSweetProducts                  0.015580\n",
      "cat_onehot__Marital_Status_Divorced    0.013203\n",
      "num__MntFruits                         0.013023\n",
      "num__age                               0.012033\n",
      "num__MntFishProducts                   0.010493\n",
      "num__Complain                          0.000000\n",
      "num__AcceptedCmp2                      0.000000\n",
      "cat_onehot__Marital_Status_Alone       0.000000\n",
      "cat_onehot__Marital_Status_Others      0.000000\n",
      "cat_onehot__Marital_Status_Widow       0.000000\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Acceder al modelo dentro del Pipeline\n",
    "xgb_model = best_model_xgb.named_steps['algoritmo']\n",
    "\n",
    "# Obtener las importancias de las características\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "if 'preprocesador' in best_model_xgb.named_steps:\n",
    "    preprocessor = best_model_xgb.named_steps['preprocesador']\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    importances_series = pd.Series(feature_importances, index=feature_names)\n",
    "    print(importances_series.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RandomForest #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       384\n",
      "           1       0.34      0.50      0.41        64\n",
      "\n",
      "    accuracy                           0.79       448\n",
      "   macro avg       0.63      0.67      0.64       448\n",
      "weighted avg       0.83      0.79      0.81       448\n",
      "\n",
      "\n",
      "##### LightGBM #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       384\n",
      "           1       0.50      0.62      0.56        64\n",
      "\n",
      "    accuracy                           0.86       448\n",
      "   macro avg       0.72      0.76      0.74       448\n",
      "weighted avg       0.87      0.86      0.86       448\n",
      "\n",
      "\n",
      "##### XGBoost #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       384\n",
      "           1       0.62      0.52      0.56        64\n",
      "\n",
      "    accuracy                           0.89       448\n",
      "   macro avg       0.77      0.73      0.75       448\n",
      "weighted avg       0.88      0.89      0.88       448\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "print('##### RandomForest #####')\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_rf))\n",
    "print()\n",
    "\n",
    "# LigthGBM\n",
    "print('##### LightGBM #####')\n",
    "y_pred_lgb = grid_lgb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_lgb))\n",
    "print()\n",
    "\n",
    "# XGBoost\n",
    "print('##### XGBoost #####')\n",
    "y_pred_xgb = grid_xgb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_xgb))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "\n",
      "LightGBM\n",
      "\n",
      "XGBoost\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RandomForest\n",
    "print('RandomForest')\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
    "disp_rf.plot()\n",
    "print()\n",
    "\n",
    "# LightGBM\n",
    "print('LightGBM')\n",
    "cm_lgb = confusion_matrix(y_test, y_pred_lgb)\n",
    "disp_lgb = ConfusionMatrixDisplay(confusion_matrix=cm_lgb)\n",
    "disp_lgb.plot()\n",
    "print()\n",
    "\n",
    "# XGBoost\n",
    "print('XGBoost')\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cm_xgb)\n",
    "disp_xgb.plot()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
